{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import helpers, preprocessing, exploration, polynomial_exp\n",
    "from helpers import split_data_rand\n",
    "from helpers import build_model_data\n",
    "from json_parser import parse_json_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from preprocessing import clean_data\n",
    "from preprocessing import balance_data\n",
    "from preprocessing import undefined_to_median, undefined_to_avg, prune_undefined\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "import os\n",
    "# Class of different styles\n",
    "class style():\n",
    "    BLACK = '\\033[30m'\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    BLUE = '\\033[34m'\n",
    "    MAGENTA = '\\033[35m'\n",
    "    CYAN = '\\033[36m'\n",
    "    WHITE = '\\033[37m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    BOLD = '\\033[1m'\n",
    "    RESET = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = pd.read_csv(\"../data/raw/x_train.csv\")\n",
    "y_df = pd.read_csv(\"../data/raw/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_data(x, y, ratio, size):\n",
    "    if size == 0: \n",
    "        print(\"Training with : 90% of [-1] and with 10% of [1] {original dataset}\")\n",
    "        balanced_x = x\n",
    "        balanced_y = y \n",
    "    else:\n",
    "        balanced_x, balanced_y = balance_data(x, y, seed=seed, size=size)\n",
    "    \n",
    "    ratio = 0.2\n",
    "    y_train, x_train, y_test, x_test = helpers.split_data_rand(balanced_y, balanced_x, ratio)\n",
    "\n",
    "    features = parse_json_file(\"features.json\")\n",
    "    x_train = clean_data(features, x_train, do_poly=False)\n",
    "    x_test = clean_data(features, x_test, do_poly=False)\n",
    "    return y_train, x_train, y_test, x_test\n",
    "\n",
    "def _print_result(model, y_test, x_test, weights):\n",
    "    test_preds = model.predict(x_test, weights)\n",
    "    test_preds[np.where(test_preds == 0)] = -1 # In case of logistic regression\n",
    "    testing_accuracy = metrics.compute_accuracy(y_test, test_preds)\n",
    "    f1_score = metrics.f1_score(y_test, test_preds)\n",
    "    \n",
    "    print(style.BOLD + f\"Loss: {loss:.4f}\" + style.RESET)\n",
    "    print(style.BOLD + style.GREEN  + f\"Test accuracy: {testing_accuracy:.4f}\" + style.RESET)\n",
    "    print(style.BOLD + style.YELLOW + f\"F1-Score: {f1_score:.4f}\" + style.RESET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m========================== Starting training for fitters ==========================\u001b[0m\n",
      "\u001b[1m\n",
      "Linear Regression GD for dataset D_1\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 90% of [-1] and with 10% of [1] {original dataset}\n",
      "\u001b[1mLoss: 0.1503\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.9099\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.1952\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression GD for dataset D_2\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 50.00% of [-1] and with 50.00% of [1]\n",
      "\u001b[1mLoss: 0.3284\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7628\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.7669\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression GD for dataset D_3\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 66.67% of [-1] and with 33.33% of [1]\n",
      "\u001b[1mLoss: 0.3119\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7677\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.6189\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression GD for dataset D_4\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 75.00% of [-1] and with 25.00% of [1]\n",
      "\u001b[1mLoss: 0.2748\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7959\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.5096\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression SGD for dataset D_1\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 90% of [-1] and with 10% of [1] {original dataset}\n",
      "SGD\n",
      "\u001b[1mLoss: 0.1538\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.9097\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.1697\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression SGD for dataset D_2\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 50.00% of [-1] and with 50.00% of [1]\n",
      "SGD\n",
      "\u001b[1mLoss: 0.4703\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.6312\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.4579\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression SGD for dataset D_3\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 66.67% of [-1] and with 33.33% of [1]\n",
      "SGD\n",
      "\u001b[1mLoss: 0.3275\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7568\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.5576\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Linear Regression SGD for dataset D_4\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 75.00% of [-1] and with 25.00% of [1]\n",
      "SGD\n",
      "\u001b[1mLoss: 0.3088\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7800\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.5988\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Regression for dataset D_1\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 90% of [-1] and with 10% of [1] {original dataset}\n",
      "\u001b[1mLoss: 0.5199\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.9137\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.0812\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Regression for dataset D_2\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 50.00% of [-1] and with 50.00% of [1]\n",
      "\u001b[1mLoss: 0.8043\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7708\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.7777\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Regression for dataset D_3\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 66.67% of [-1] and with 33.33% of [1]\n",
      "\u001b[1mLoss: 0.7721\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7796\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.6394\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Regression for dataset D_4\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 75.00% of [-1] and with 25.00% of [1]\n",
      "\u001b[1mLoss: 0.7259\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.8058\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.5270\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Logistic Regression GD for dataset D_1\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 90% of [-1] and with 10% of [1] {original dataset}\n",
      "\u001b[1mLoss: -2.6460\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.9128\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.0569\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Logistic Regression GD for dataset D_2\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 50.00% of [-1] and with 50.00% of [1]\n",
      "\u001b[1mLoss: -0.0379\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7464\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.7240\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Logistic Regression GD for dataset D_3\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 66.67% of [-1] and with 33.33% of [1]\n",
      "\u001b[1mLoss: -0.6444\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7645\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.5556\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Logistic Regression GD for dataset D_4\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 75.00% of [-1] and with 25.00% of [1]\n",
      "\u001b[1mLoss: -1.1712\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7953\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.4183\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Logisitc Regression GD for dataset D_1\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 90% of [-1] and with 10% of [1] {original dataset}\n",
      "\u001b[1mLoss: -2.6212\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.9128\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.0515\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Logisitc Regression GD for dataset D_2\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 50.00% of [-1] and with 50.00% of [1]\n",
      "\u001b[1mLoss: -0.0302\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7458\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.7231\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Logisitc Regression GD for dataset D_3\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 66.67% of [-1] and with 33.33% of [1]\n",
      "\u001b[1mLoss: -0.6334\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7638\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.5525\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[1m\n",
      "Ridge Logisitc Regression GD for dataset D_4\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "Training with : 75.00% of [-1] and with 25.00% of [1]\n",
      "\u001b[1mLoss: -1.1553\u001b[0m\n",
      "\u001b[1m\u001b[32mTest accuracy: 0.7944\u001b[0m\n",
      "\u001b[1m\u001b[33mF1-Score: 0.4123\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\u001b[34m===================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "import fitters\n",
    "import metrics\n",
    "seed = 100\n",
    "degree = 1\n",
    "\n",
    "x = x_df.values\n",
    "y = y_df[\"_MICHD\"].values\n",
    "\n",
    "print(style.BLUE + \"========================== Starting training for fitters ==========================\" + style.RESET)\n",
    "\n",
    "# Linear Regression GD\n",
    "for size in [0,1,2,3]:\n",
    "    print(style.BOLD + f\"\\nLinear Regression GD for dataset D_{size + 1}\" + style.RESET)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    ratio = 0.2\n",
    "    y_train, x_train, y_test, x_test = _prepare_data(x, y, ratio, size)\n",
    "    gm = fitters.GradientFitter(y_train, x_train, y_test, x_test, 10000, 0.001)\n",
    "    w, loss = gm.fit()\n",
    "    _print_result(gm, y_test, x_test, w)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    \n",
    "# Linear Regression SGD\n",
    "for size in [0,1,2,3]:\n",
    "    print(style.BOLD + f\"\\nLinear Regression SGD for dataset D_{size + 1}\" + style.RESET)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    ratio = 0.2\n",
    "    y_train, x_train, y_test, x_test = _prepare_data(x, y, ratio, size)\n",
    "    sgm = fitters.StochasticGradientFitter(y_train, x_train, y_test, x_test, 10000, 0.001)\n",
    "    w, loss = sgm.fit()\n",
    "    _print_result(sgm, y_test, x_test, w)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "\n",
    "# Least Square (Singular Matrix problem)\n",
    "# for size in [0,1,2,3]:\n",
    "#     print(style.BOLD + f\"\\nLinear Regression GD for dataset D_{size + 1}\" + style.RESET)\n",
    "#     print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "#     ratio = 0.2\n",
    "#     y_train, x_train, y_test, x_test = _prepare_data(x, y, ratio, size)\n",
    "#     lsq = fitters.LeastSquareFitter(y_train, x_train, y_test, x_test)\n",
    "#     w, loss = lsq.fit()\n",
    "#     _print_result(lsq, y_test, x_test, w)\n",
    "#     print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "\n",
    "# Ridge Regression \n",
    "for size in [0,1,2,3]:\n",
    "    print(style.BOLD + f\"\\nRidge Regression for dataset D_{size + 1}\" + style.RESET)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    ratio = 0.2\n",
    "    y_train, x_train, y_test, x_test = _prepare_data(x, y, ratio, size)\n",
    "    rrf = fitters.RidgeRegressionFitter(y_train, x_train, y_test, x_test, 10e-7)\n",
    "    w, loss = rrf.fit()\n",
    "    _print_result(rrf, y_test, x_test, w)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "\n",
    "# Logistic Regression\n",
    "for size in [0,1,2,3]:\n",
    "    print(style.BOLD + f\"\\nLogistic Regression GD for dataset D_{size + 1}\" + style.RESET)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    ratio = 0.2\n",
    "    y_train, x_train, y_test, x_test = _prepare_data(x, y, ratio, size)\n",
    "    y_train[np.where(y_train == -1)] = 0\n",
    "    lg = fitters.LogisticRegressionFitter(y_train, x_train, y_test, x_test, 10000, 0.005)\n",
    "    w, loss = lg.fit()\n",
    "    _print_result(lg, y_test, x_test, w)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "\n",
    "# Ridge Logistic Regression\n",
    "for size in [0,1,2,3]:\n",
    "    print(style.BOLD + f\"\\nRidge Logisitc Regression GD for dataset D_{size + 1}\" + style.RESET)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    ratio = 0.2\n",
    "    y_train, x_train, y_test, x_test = _prepare_data(x, y, ratio, size)\n",
    "    y_train[np.where(y_train == -1)] = 0\n",
    "    rlg = fitters.RegLogisticRegressionFitter(y_train, x_train, y_test, x_test, 10000, 0.005, 10e-4)\n",
    "    w, loss = rlg.fit()\n",
    "    _print_result(rlg, y_test, x_test, w)\n",
    "    print(\"========================================================================\".replace(\"=\", \"-\"))\n",
    "    \n",
    "print(style.BLUE + \"===================================================================================\" + style.RESET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/francoisdumoncel/Library/Mobile Documents/com~apple~CloudDocs/Desktop/02-EPFL/MA1/ML/ml-project1/notebooks/new.ipynb Cellule 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/francoisdumoncel/Library/Mobile%20Documents/com~apple~CloudDocs/Desktop/02-EPFL/MA1/ML/ml-project1/notebooks/new.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x_true \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../data/raw/x_test.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/francoisdumoncel/Library/Mobile%20Documents/com~apple~CloudDocs/Desktop/02-EPFL/MA1/ML/ml-project1/notebooks/new.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ids \u001b[39m=\u001b[39m x_true\u001b[39m.\u001b[39mId\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/francoisdumoncel/Library/Mobile%20Documents/com~apple~CloudDocs/Desktop/02-EPFL/MA1/ML/ml-project1/notebooks/new.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x_true \u001b[39m=\u001b[39m clean_data(features, x_true\u001b[39m.\u001b[39mvalues, do_poly\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/francoisdumoncel/Library/Mobile%20Documents/com~apple~CloudDocs/Desktop/02-EPFL/MA1/ML/ml-project1/notebooks/new.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_preds \u001b[39m=\u001b[39m rrf\u001b[39m.\u001b[39mpredict(x_true, w)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/francoisdumoncel/Library/Mobile%20Documents/com~apple~CloudDocs/Desktop/02-EPFL/MA1/ML/ml-project1/notebooks/new.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m helpers\u001b[39m.\u001b[39mcreate_csv_submission(ids, test_preds, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtestRRF-\u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "if size==3:\n",
    "        x_true = pd.read_csv(\"../data/raw/x_test.csv\")\n",
    "        ids = x_true.Id\n",
    "        x_true = clean_data(features, x_true.values, do_poly=False)\n",
    "        test_preds = rrf.predict(x_true, w)\n",
    "        helpers.create_csv_submission(ids, test_preds, f\"testRRF-{size}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
